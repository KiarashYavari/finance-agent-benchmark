#
# Stores environment (secret) variables for the Finance-Agent-Benchmark. 
#
# NOTE: For the LLM, the app uses: 
#       1) LLM_MODEL   
#       2) LLM_API_KEY
#        
# https://docs.litellm.ai/docs/providers
# https://docs.aimlapi.com/api-references/text-models-llm
# 
# HuggingFace Models: https://huggingface.co/models
#

# ---- LLM Models (litellm style) ----
LLM_MODEL=gemini/gemini-2.5-flash-lite
HF_LLM_MODEL=huggingface/Qwen/Qwen3-Next-80B-A3B-Instruct  # Hugging Face
OR_LLM_MODEL=openrouter/deepseek/deepseek-chat-v3.1:free   # Open Router

#LLM_MODEL=openai/gpt-4o
#LLM_MODEL=anthropic/claude-3-haiku
#LLM_MODEL=grok/grok-3
#LLM_MODEL=groq/llama3-8b-8192
#LLM_MODEL=together/mistral-7b-instruct
#LLM_MODEL=ollama/llama3.1
#LLM_MODEL=openrouter/meta-llama/llama-3-8b-instruct:free
#LLM_MODEL=anthropic/claude-3.5-sonnet
#LLM_MODEL=huggingface/MiniMaxAI/MiniMax-M2 # This works

# ---- Debug & Others ----
LITELLM_LOG=DEBUG
VERBOSE=1       # 1=True 0=False
SAFETY_CHECK=0  # 1=True 0=False - To perfomer or not safety check

# ---- API keys ----
LLM_API_KEY=<you api-key here>
HF_LLM_API_KEY=<you api-key here> # Hugging Face
OR_LLM_API_KEY= # Open Router

SEC_API_KEY=your_key_here
SERP_API_KEY=your-serpapi-key
OPENAI_API_KEY=

# ---- googleapi.com ----
GOOGLE_SEARCH_API_KEY=your-real-api-key-here
GOOGLE_CX=your-cx-id-here

# ---- ports / hosts (local) ----
GREEN_AGENT_HOST=127.0.0.1
GREEN_AGENT_PORT=9000
GREEN_AGENT_NUM_TASKS=5  # Number tasks to process (Overriden by --num_tasks parameter)
GREEN_CARD=cards/green_card.toml

MCP_HOST=127.0.0.1
MCP_PORT=9001

WHITE_AGENT_HOST=127.0.0.1
WHITE_AGENT_PORT=8000
WHITE_AGENT_MAX_ITER=5  # Max ierations for each task in white_agent
WHITE_CARD=cards/white_card.toml

# ---- paths ----
SCHEMA_FILE=mcp_schema.json
#DATASET=data/Financial-QA-10k.csv
DATASET=data/public.csv
USE_DISK_CACHE=1  # 1=True 0=False - To save SEC Filings to disk

